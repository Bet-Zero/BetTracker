---
name: audit-review
description: Review an existing Apex Audit file and build a structured Fix Plan.
---

You are running the **/audit-review** command in Cursor.

The user is NOT asking for a new audit.  
They are asking you to review an existing Apex Audit result and turn it into a safe, ordered **Fix Plan** that other commands can execute.

---

## INPUT REQUIREMENTS

The user MUST tag exactly one existing audit markdown file when calling this command, for example:

- `/audit-review @audits/codebase-audit.md`
- `/audit-review @audits/parsing-module-audit.md`

Rules:

- The tagged file is the ONLY audit input you should use.
- Do NOT guess or pick a different audit file.
- You MAY also read `#codebase` (and any extra tagged files or folders) **only** to verify whether issues are still valid.

If the user does NOT tag an audit file:

- Do NOT run anything.
- Reply in chat with:

  > I need you to tag the specific audit markdown file, for example:  
  > `/audit-review @audits/codebase-audit.md`

---

## CORE BEHAVIOR

- Load and follow the full instructions stored in:  
  `docs/AuditReviewPrompt.md`

- Treat the tagged audit file as the source **diagnosis**.  
  You are creating a refined, execution-ready **treatment plan**, NOT re-running a fresh audit.

- For **each issue** in the audit (including duplicates/overlapping implementations, architectural issues, correctness problems, and cleanup items):

  - Parse and normalize it as described in `docs/AuditReviewPrompt.md`.
  - Double-check it against the current codebase:

    - Confirm whether the issue still exists.
    - Adjust severity if necessary.
    - Drop it if it is clearly obsolete.

  - Assign:
    - **Review status**: `CONFIRMED` / `ADJUSTED` / `REJECTED`
    - **Fix-safety flag**:
      - `SAFE_AUTO` — can be safely automated by tools like `/fix-all`
      - `NEEDS_CONTEXT` — technically automatable but requires more local inspection, tests, or checks
      - `NEEDS_DECISION` — requires a human product/architecture decision (for example: choosing a canonical implementation among duplicates)

- Pay special attention to **duplicate or overlapping implementations** noted in the audit:

  - Keep track of:
    - Which versions exist
    - Which one appears to be the canonical / currently used implementation
  - Make sure the Fix Plan includes clear steps for:
    - Confirming the canonical choice
    - Updating callers to the canonical module
    - Archiving or deleting unused variants (once confirmed)
    - Updating documentation to reflect the canonical implementation

---

## FIX PLAN FILE GENERATION

Create a new **Fix Plan** markdown file in the `audits/` directory.

- Use the same base filename as the source audit and append `_fixplan` before the extension.

Examples:

- Source audit: `audits/codebase-audit.md`  
  Fix Plan: `audits/codebase-audit_fixplan.md`

- Source audit: `audits/parsing-module-audit.md`  
  Fix Plan: `audits/parsing-module-audit_fixplan.md`

The Fix Plan must be structured exactly as defined in `docs/AuditReviewPrompt.md`, with at least:

1. **Header**

   - Title
   - Source audit path
   - Generated by (`/audit-review`)
   - Date/time

2. **Summary**

   - Counts by severity (Critical / High / Medium / Low)
   - Counts by fix-safety (`SAFE_AUTO` / `NEEDS_CONTEXT` / `NEEDS_DECISION`)
   - Count of issues that were:
     - Confirmed
     - Adjusted
     - Rejected as obsolete

3. **Ordered Fix Steps**

   Present the work in a practical sequence, for example:

   - **Step 1 — Critical SAFE_AUTO issues**
   - **Step 2 — Remaining Critical and High issues (including NEEDS_CONTEXT)**
   - **Step 3 — Medium and Low issues**
   - **Items Requiring Human Decision**  
     (all `NEEDS_DECISION` issues, including canonicalization of duplicate/overlapping implementations)

   For each issue, include:

   - A stable **Issue ID** (can be derived from the original audit)
   - Fix-safety flag (`SAFE_AUTO` / `NEEDS_CONTEXT` / `NEEDS_DECISION`)
   - Severity (Critical / High / Medium / Low)
   - Review status (CONFIRMED / ADJUSTED / REJECTED)
   - Files involved
   - **What’s wrong (confirmed)** — short, plain English
   - **How to fix (clarified)** — step-by-step, non-diff language that other commands can follow
   - **Impact** — why this matters (correctness, safety, performance, maintainability, simplification, canonicalization, etc.)

   For duplicate/overlapping implementations, ensure the “How to fix” steps clearly describe:

   - Which implementation to treat as canonical
   - How to migrate callers
   - When and how to archive/remove the others
   - Any documentation or type updates needed

4. **Index or Table of Contents (Optional but Helpful)**
   - Especially for large audits, include a short index so follow-up commands can target specific sections.

---

## OPTIONAL NOTE ON ORIGINAL AUDIT

You MAY optionally add a small note at the top of the original audit file, for example:

> Reviewed by `/audit-review` on \<date>.  
> See `audits/<..._fixplan.md>` for the structured Fix Plan.

Do NOT rewrite or heavily modify the original audit; it is the historical **diagnosis**.  
The Fix Plan is the refined, execution-ready **plan**.

---

## CHAT RESPONSE STYLE

After generating the Fix Plan:

- Keep your response short, human, and focused.
- Do NOT paste full files or diffs in chat.

Respond with something like:

- `Reviewed audit: audits/codebase-audit.md`
- `Created Fix Plan: audits/codebase-audit_fixplan.md`
- A few bullets summarizing counts, for example:
  - `Critical: 3 (2 SAFE_AUTO, 1 NEEDS_DECISION)`
  - `High: 5 (3 SAFE_AUTO, 2 NEEDS_CONTEXT)`
  - `Medium: 7 (all SAFE_AUTO)`
  - `Low: 4 (all SAFE_AUTO)`
  - `1 issue removed as obsolete; 2 severities adjusted.`
- A simple next step suggestion, for example:
  - `Next: use /fix-all @audits/codebase-audit_fixplan.md to auto-apply SAFE_AUTO items.`

Always assume the user will NOT apply fixes manually.  
This Fix Plan will be consumed by **other commands** (like `/fix-all`, `/doc-sync`, or a future `/dedupe`) that directly edit the code.

Your job is to make that downstream automation **safe, ordered, and crystal clear.**
