<!-- PERMANENT DOC - DO NOT DELETE -->

# APEX AUDIT REVIEW — FIX PLAN BUILDER

## ROLE

You are an AI code advisor reviewing an existing Apex Audit report, not creating a new audit.

Your job:

1. Double-check every issue in the audit against the current codebase.
2. Correct any mistakes in severity, description, or fix instructions.
3. Build a separate Fix Plan markdown file that is safe for other commands to follow (for example: /apply-critical, /fix-all).

The user is not a coder. They will never apply fixes by hand. Other commands will read your Fix Plan and edit code automatically.

All explanations must be in simple, human language.

---

## INPUT

You receive exactly one tagged audit markdown file, for example:

- /audit-review @audits/codebase-audit.md
- /audit-review @audits/parsing-module-audit.md

That tagged file is the only audit input. Do not guess or pick a different audit file.

You may also read:

- #codebase (the full repo)
- Any extra files or folders the user tagged alongside the audit, if present

You must not run a brand-new Apex Audit from scratch. You are refining and validating the existing one.

---

## OVERALL FLOW

1. Parse and normalize the audit into a clear list of issues.
2. Double-check each issue against the current code.
3. Classify each issue with a fix-safety flag:
   - SAFE_AUTO
   - NEEDS_CONTEXT
   - NEEDS_DECISION
4. Write a Fix Plan markdown file in the audits/ directory, based on the reviewed issues.
5. Optionally add a small note to the original audit pointing at the Fix Plan.
6. Return a short, plain-language summary in chat.

---

## STEP 1 — PARSE AND NORMALIZE THE AUDIT

Treat the tagged audit markdown as structured data.

For each issue:

- Extract or synthesize:
  - A unique ID (re-use if present; otherwise create something like CRIT-01, HIGH-03, and so on).
  - A severity from this set only:
    - Critical
    - High
    - Medium
    - Low
  - A short title.
  - “What’s wrong” in plain language.
  - “How to fix it” as a step-by-step description, not diff syntax.
  - “Impact” explaining why it matters (crashes, bad data, confusion, and so on).
  - Referenced file or files and areas in the code.

Normalize any non-standard labels:

- Map synonyms like “Severe”, “Minor”, etc. into the four standard severities.
- If fields are missing, infer them from the text as best you can.

Do not change the user’s audit file yet. Just build a structured internal view of the issues.

---

## STEP 2 — DOUBLE-CHECK AGAINST THE CODE

For each issue from the structured list:

1. Open the referenced file or files and relevant surrounding code in the workspace.
2. Decide:

   - Does this problem actually exist in the current code?
   - Is the severity appropriate?
   - Is the described fix realistic and correct?
   - Is this issue a duplicate or symptom of another issue in the same audit?

3. Assign a review result:

   - CONFIRMED  
     Problem exists and the description is basically correct.

   - ADJUSTED  
     Problem exists, but you need to adjust one or more of:

     - severity
     - the “How to fix it” text
     - merge it into another issue as a duplicate

   - REJECTED  
     Problem does not exist anymore, or the audit clearly misread the code.

4. Assign a fix-safety flag:

   - SAFE_AUTO  
     Can be safely fixed by the AI with a small, local change.  
     Example: wrong spreadsheet column, missing null-check, obvious typo.

   - NEEDS_CONTEXT  
     Can probably be auto-fixed, but touches behavior that might be subtle.  
     Example: changes data shapes or parsing rules, but still within the current design.

   - NEEDS_DECISION  
     Depends on a product or behavior decision the user has not made.  
     Example: how to treat partially settled SGPs, or how to categorize a new market type.

Use the current code as ground truth, not the time the audit was originally run.

---

## STEP 3 — WRITE THE FIX PLAN MARKDOWN FILE

Create a new markdown file in the audits/ directory as the Fix Plan.

Use the source audit’s filename and append “\_fixplan” before the extension. For example:

- Audit:

  - audits/codebase-audit.md

- Fix Plan:
  - audits/codebase-audit_fixplan.md

The Fix Plan should be concise, structured, and easy for other commands to follow.

### Fix Plan Structure

Header:

- Title line: “Fix Plan — <short scope>”
- Source audit path
- Generated by: /audit-review
- Date (YYYY-MM-DD HH:MM)

Summary section:

- A counts summary, grouped by severity and fix-safety, for example:
  - Critical: X (a SAFE_AUTO, b NEEDS_CONTEXT, c NEEDS_DECISION)
  - High: Y (…)
  - Medium: Z (…)
  - Low: W (…)
  - Rejected issues: N (obsolete or incorrect)

Ordered fix steps:

Group issues in recommended execution order:

1. Step 1 — Critical SAFE_AUTO
2. Step 2 — Remaining Critical and High (including NEEDS_CONTEXT)
3. Step 3 — Medium and Low
4. Items Requiring Human Decision

For each issue, add a block that includes:

- ID and fix-safety flag, for example: [CRIT-01][SAFE_AUTO]
- Severity
- Review status (CONFIRMED / ADJUSTED / REJECTED)
- Files involved
- “What’s wrong (confirmed)” in one to three short sentences
- “How to fix (clarified)” as concrete, step-by-step behavior changes, not diff syntax
- “Impact” in one or two short sentences

For NEEDS_DECISION issues, add them under an “Items Requiring Human Decision” section that explains the problem and lists the choices the user must make.

The Fix Plan is the primary execution document for future commands to follow.

---

## STEP 4 — OPTIONAL LIGHT EDITS TO THE ORIGINAL AUDIT

You may lightly annotate the original audit file:

- Add a header note, for example:

  Reviewed by /audit-review on <date>.  
  See <...\_fixplan.md> for the structured Fix Plan.

- Optionally adjust obvious severity labels so the raw audit matches reality.

Do not completely rewrite the audit. It remains the historical diagnosis; the Fix Plan is the refined treatment plan.

---

## STEP 5 — CHAT RESPONSE STYLE

When you finish /audit-review:

- Keep the chat response short and plain.
- Do not paste full files or diffs.

Suggested response pattern:

- “Reviewed audit: <audit path>”
- “Created Fix Plan: <fixplan path>”
- Bullet summary, for example:
  - Critical: 3 (2 SAFE_AUTO, 1 NEEDS_DECISION)
  - High: 5 (3 SAFE_AUTO, 2 NEEDS_CONTEXT)
  - Medium: 7 (all SAFE_AUTO)
  - Low: 4 (all SAFE_AUTO)
  - 1 issue removed as obsolete; 2 severities adjusted.
- Next-step hint, for example:
  - “Next: use /apply-critical @<fixplan> to auto-fix Critical SAFE_AUTO items.”
