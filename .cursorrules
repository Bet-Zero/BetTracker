# Custom Cursor Commands
# Commands defined here will be available via /command-name in Cursor chat

commands:
  - name: audit
    description: Run the Apex Audit on the selected files, folders, or full codebase.
    prompt: |
      You are running the /audit command in Cursor.
      The user selects the TARGET_SCOPE using @-mentions or #codebase.

      Load and follow the full audit instructions stored in:
      docs/ApexAuditPrompt.md

      Treat the selected scope as TARGET_SCOPE.
      Perform the complete Apex Audit exactly as described in that file.

      Produce the full audit output in chat AND,
      if file editing is supported,
      also create or update a Markdown file under the `audits/` directory
      containing the full audit.

      Name the audit file based on the selection:
        - Single file: audits/<filename>-audit.md
        - Folder: audits/<folder-name>-audit.md
        - Entire codebase: audits/codebase-audit.md

  - name: audit-review
    description: Review an existing Apex Audit file and build a structured Fix Plan.
    prompt: |
      You are running the /audit-review command in Cursor.

      The user is NOT asking for a new audit.
      They are asking you to review an existing Apex Audit result and turn it into a safe, ordered Fix Plan.

      REQUIREMENTS FOR INPUT

      - The user MUST tag exactly one existing audit markdown file when calling this command,
        for example:
          /audit-review @audits/codebase-audit.md

      - That tagged file is the ONLY audit input you should use.
      - Do NOT guess or pick a different audit file.
      - You may also read #codebase (and any extra tagged files or folders) to verify issues.

      If the user does NOT tag an audit file:
      - Do NOT run anything.
      - Reply in chat with:
        "I need you to tag the specific audit markdown file, for example:
        /audit-review @audits/codebase-audit.md"

      CORE BEHAVIOR

      1) Load and follow the full instructions stored in:
         docs/AuditReviewPrompt.md

         That file defines:
         - How to parse and normalize the audit issues.
         - How to double-check each issue against the current code.
         - How to classify each issue with:
             - review status: CONFIRMED / ADJUSTED / REJECTED
             - fix-safety flag: SAFE_AUTO / NEEDS_CONTEXT / NEEDS_DECISION
         - How to structure the Fix Plan.

      2) Treat the tagged audit file as the source "diagnosis".
         You are creating a refined "treatment plan" from it, NOT re-running a fresh audit.

      3) Create a new Fix Plan markdown file in the `audits/` directory.

         - Use the same base filename as the source audit and append `_fixplan`
           before the extension. For example:
             Source audit: audits/codebase-audit.md
             Fix Plan:     audits/codebase-audit_fixplan.md

         - The Fix Plan MUST include:
           - A header with:
             - Title (Fix Plan — <short scope>)
             - Source audit path
             - Generated by: /audit-review
             - Date
           - A summary section with counts by severity and fix-safety:
             - Critical: X (a SAFE_AUTO, b NEEDS_CONTEXT, c NEEDS_DECISION)
             - High: Y (…)
             - Medium: Z (…)
             - Low: W (…)
             - Rejected issues: N
           - Ordered fix steps, grouped as:
             - Step 1 — Critical SAFE_AUTO issues
             - Step 2 — Remaining Critical and High issues (including NEEDS_CONTEXT)
             - Step 3 — Medium and Low issues
             - Items Requiring Human Decision (all NEEDS_DECISION issues)
           - For each issue:
             - ID and fix-safety flag (for example: [CRIT-01][SAFE_AUTO])
             - Severity
             - Review status (CONFIRMED / ADJUSTED / REJECTED)
             - Files involved
             - "What’s wrong (confirmed)" in 1–3 short, plain sentences
             - "How to fix (clarified)" as concrete, step-by-step behavior changes
               (no diff syntax; describe intent and behavior)
             - "Impact" in 1–2 short sentences

      4) You MAY optionally add a small note to the top of the original audit file, for example:
         "Reviewed by /audit-review on <date>. See <..._fixplan.md> for the structured Fix Plan."

         Do NOT completely rewrite the original audit; it is the historical diagnosis.
         The Fix Plan is the refined, execution-ready plan.

      CHAT RESPONSE STYLE

      After generating the Fix Plan:

      - Keep your response short and human.
      - Do NOT paste full files or diffs.

      Respond with something like:

      - "Reviewed audit: <audit path>"
      - "Created Fix Plan: <fixplan path>"
      - A few bullets summarizing counts, for example:
        - Critical: 3 (2 SAFE_AUTO, 1 NEEDS_DECISION)
        - High: 5 (3 SAFE_AUTO, 2 NEEDS_CONTEXT)
        - Medium: 7 (all SAFE_AUTO)
        - Low: 4 (all SAFE_AUTO)
        - 1 issue removed as obsolete; 2 severities adjusted.
      - A simple next step suggestion, for example:
        - "Next: use /apply-critical @<fixplan> to auto-fix Critical SAFE_AUTO items."

      Always assume the user will NOT apply fixes manually.
      This Fix Plan will be consumed by other commands that directly edit the code.
